{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "We'll take a tour of the methods for classification in sklearn. First let's load a toy dataset to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert it to a dataframe for better visuals\n",
    "df = pd.DataFrame(breast.data)\n",
    "df.columns = breast.feature_names\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now look at the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(breast.target_names)\n",
    "breast.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the scikit learn models is basically the same as in Julia's ScikitLearn.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cart = DecisionTreeClassifier(max_depth=2, min_samples_leaf=140)\n",
    "cart.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper function to plot the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Graphviz (tedious)\n",
    "\n",
    "## Windows\n",
    "\n",
    "1. Download graphviz from https://graphviz.gitlab.io/_pages/Download/Download_windows.html\n",
    "2. Install it by running the .msi file\n",
    "3. Set the pat variable:\n",
    "    (a) Go to Control Panel > System and Security > System > Advanced System Settings >  Environment Variables > Path > Edit\n",
    "    (b) Add 'C:\\Program Files (x86)\\Graphviz2.38\\bin'\n",
    "4. Run `conda install graphviz`\n",
    "5. Run `conda install python-graphviz`\n",
    "\n",
    "## macOS and Linux\n",
    "\n",
    "1. Run `brew install graphviz` (install `brew` from https://docs.brew.sh/Installation if you don't have it)\n",
    "2. Run `conda install graphviz`\n",
    "3. Run `conda install python-graphviz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import sklearn.tree\n",
    "def visualize_tree(sktree):\n",
    "    dot_data = sklearn.tree.export_graphviz(sktree, out_file=None, \n",
    "                                    filled=True, rounded=True,  \n",
    "                                    special_characters=False,\n",
    "                                    feature_names=df.columns)\n",
    "    return graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tree(cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can get the label predictions with the `.predict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cart.predict(breast.data)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly the predicted probabilities with `.predict_proba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = cart.predict_proba(breast.data)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in Julia, the probabilities are returned for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the second column of the probs by slicing, just like how we did it in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = cart.predict_proba(breast.data)[:,1]\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we can use functions from `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(breast.target, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests and Boosting\n",
    "\n",
    "We use random forests and boosting in the same way as CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = forest.predict(breast.data)\n",
    "probs = forest.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "boost = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)\n",
    "boost.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = boost.predict(breast.data)\n",
    "probs = boost.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We can also access logistic regression from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression()\n",
    "logit.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = logit.predict(breast.data)\n",
    "probs = logit.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn implementation has options for regularization in logistic regression. You can choose between L1 and L2 regularization:\n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/math/6a0bcf21baaeb0c2b879ab74fe333c0aab0d6ae6.png)\n",
    "\n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/math/760c999ccbc78b72d2a91186ba55ce37f0d2cf37.png)\n",
    "\n",
    "Note that this regularization is adhoc and **not equivalent to robustness**. For a robust logistic regression, follow the approach from 15.680.\n",
    "\n",
    "You control the regularization with the `penalty` and `C` hyperparameters. We can see that our model above used L2 regularization with $C=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try out unregularized logistic regression as well as L1 regularization. Which of the three options seems best? What if you try changing $C$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No regularization\n",
    "logit = LogisticRegression(C=1e10)\n",
    "logit.fit(breast.data, breast.target)\n",
    "labels = logit.predict(breast.data)\n",
    "probs = logit.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 regularization\n",
    "logit = LogisticRegression(C=100, penalty='l1')\n",
    "logit.fit(breast.data, breast.target)\n",
    "labels = logit.predict(breast.data)\n",
    "probs = logit.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Now let's take a look at regression in sklearn. Again we can start by loading up a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(boston.data)\n",
    "df.columns = boston.feature_names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees\n",
    "\n",
    "We use regression trees in the same way as classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "cart = DecisionTreeRegressor(max_depth=2, min_samples_leaf=5)\n",
    "cart.fit(boston.data, boston.target)\n",
    "visualize_tree(cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like for classification, we get the predicted labels out with the `.predict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cart.predict(boston.data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are functions provided by `sklearn.metrics` to evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests and Boosting\n",
    "\n",
    "Random forests and boosting for regression work the same as in classification, except we use the `Regressor` version rather than `Classifier`.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Test and compare the (in-sample) performance of random forests and boosting on the Boston data with some sensible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(boston.data, boston.target)\n",
    "preds = forest.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "boost = GradientBoostingRegressor(n_estimators=100, learning_rate=0.2)\n",
    "boost.fit(boston.data, boston.target)\n",
    "preds = boost.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a large collection of linear regression models in sklearn. Let's start with a simple ordinary linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear = LinearRegression()\n",
    "linear.fit(boston.data, boston.target)\n",
    "preds = linear.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the betas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use regularized models as well. Here is ridge regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(boston.data, boston.target)\n",
    "preds = ridge.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(boston.data, boston.target)\n",
    "preds = lasso.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other linear regression models available. See the [linear model documentation](http://scikit-learn.org/stable/modules/linear_model.html) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "The elastic net is another linear regression method that combines ridge and lasso regularization. Try running it on this dataset, referring to the documentation as needed to learn how to use it and control the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
